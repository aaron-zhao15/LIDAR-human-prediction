{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started: Display MoGaze data with humoro\n",
    "\n",
    "This notebook describes how to get started using the [MoGaze dataset](https://humans-to-robots-motion.github.io/mogaze/) with our pybullet based library [humoro](https://github.com/PhilippJKratzer/humoro).\n",
    "\n",
    "\n",
    "## Installation\n",
    "The installation is tested on Ubuntu 18.04.\n",
    "\n",
    "The packages python3 and python3-pip need to be installed and upgraded (skip if python already is installed):\n",
    "```bash\n",
    "sudo apt install python3\n",
    "sudo apt install python3-pip\n",
    "python3 -m pip install --upgrade pip --user\n",
    "```\n",
    "\n",
    "For parts of the software qt5 is used, it can be installed using:\n",
    "```bash\n",
    "sudo apt install qt5-default\n",
    "```\n",
    "\n",
    "Clone the repository:\n",
    "```bash\n",
    "git clone https://github.com/PhilippJKratzer/humoro.git\n",
    "```\n",
    "\n",
    "The requirements can be installed using:\n",
    "```bash\n",
    "cd humoro\n",
    "python3 -m pip install -r requirements.txt --user\n",
    "```\n",
    "    \n",
    "Finally, you can install humoro system-wide using:\n",
    "```bash\n",
    "sudo python3 setup.py install\n",
    "```\n",
    "\n",
    "Download the dataset files:\n",
    "```bash\n",
    "wget pkratzer.net/mogaze.zip\n",
    "unzip mogaze.zip\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playback Human data\n",
    "Let's first have a closer look into the human data only. We can load a trajectory from file using the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from humoro.trajectory import Trajectory\n",
    "\n",
    "full_traj = Trajectory()\n",
    "full_traj.loadTrajHDF5(\"humoro/mogaze/p2_1_human_data.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trajectory contains a data array, a description of the joints and some fixed joints for scaling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has dimension timeframe, state_size:\n",
      "(164399, 66)\n",
      "\n",
      "This is a list of jointnames (from the urdf) corresponding to the state dimensions:\n",
      "['baseTransX', 'baseTransY', 'baseTransZ', 'baseRotX', 'baseRotY', 'baseRotZ', 'pelvisRotX', 'pelvisRotY', 'pelvisRotZ', 'torsoRotX', 'torsoRotY', 'torsoRotZ', 'neckRotX', 'neckRotY', 'neckRotZ', 'headRotX', 'headRotY', 'headRotZ', 'linnerShoulderRotX', 'linnerShoulderRotY', 'linnerShoulderRotZ', 'lShoulderRotX', 'lShoulderRotY', 'lShoulderRotZ', 'lElbowRotX', 'lElbowRotY', 'lElbowRotZ', 'lWristRotX', 'lWristRotY', 'lWristRotZ', 'rinnerShoulderRotX', 'rinnerShoulderRotY', 'rinnerShoulderRotZ', 'rShoulderRotX', 'rShoulderRotY', 'rShoulderRotZ', 'rElbowRotX', 'rElbowRotY', 'rElbowRotZ', 'rWristRotX', 'rWristRotY', 'rWristRotZ', 'lHipRotX', 'lHipRotY', 'lHipRotZ', 'lKneeRotX', 'lKneeRotY', 'lKneeRotZ', 'lAnkleRotX', 'lAnkleRotY', 'lAnkleRotZ', 'lToeRotX', 'lToeRotY', 'lToeRotZ', 'rHipRotX', 'rHipRotY', 'rHipRotZ', 'rKneeRotX', 'rKneeRotY', 'rKneeRotZ', 'rAnkleRotX', 'rAnkleRotY', 'rAnkleRotZ', 'rToeRotX', 'rToeRotY', 'rToeRotZ']\n",
      "\n",
      "Some joints are used for scaling the human and do not change over time\n",
      "They are available in a dictionary:\n",
      "{'pelvisTransX': -1.1192353636636596e-10, 'pelvisTransY': -2.022968117329814e-10, 'pelvisTransZ': 0.08061984928961385, 'torsoTransX': 3.6286035364046447e-05, 'torsoTransY': -8.98198109463855e-05, 'torsoTransZ': 0.20326695569369413, 'neckTransX': -4.4229605238600666e-10, 'neckTransY': -3.362181708381348e-10, 'neckTransZ': 0.23465491876455302, 'headTransX': 1.8709009654750528e-07, 'headTransY': -0.01931395181998416, 'headTransZ': 0.1496814832053956, 'linnerShoulderTransX': 0.039334774581112876, 'linnerShoulderTransY': 0.003766178967395888, 'linnerShoulderTransZ': 0.18217331197412007, 'lShoulderTransX': 0.159927878991861, 'lShoulderTransY': -2.8152120167936126e-10, 'lShoulderTransZ': -7.344543800436504e-10, 'lElbowTransX': 0.2671021385502232, 'lElbowTransY': 3.2235849065739266e-09, 'lElbowTransZ': 1.3428751631796705e-08, 'lWristTransX': 0.27452203939032244, 'lWristTransY': -0.0011901673425819702, 'lWristTransZ': 0.00019837696856255194, 'rinnerShoulderTransX': -0.039132775306836384, 'rinnerShoulderTransY': 0.0037661790257647013, 'rinnerShoulderTransZ': 0.1821733121595246, 'rShoulderTransX': -0.15992787921766244, 'rShoulderTransY': 5.246358377589178e-10, 'rShoulderTransZ': 1.1905357122351634e-10, 'rElbowTransX': -0.267102135481079, 'rElbowTransY': 2.748363481257103e-09, 'rElbowTransZ': 8.590998570946257e-09, 'rWristTransX': -0.2771445932734951, 'rWristTransY': -0.0024910636574316915, 'rWristTransZ': 0.001200257775570811, 'lHipTransX': 0.09831689553439996, 'lHipTransY': 8.816048017459143e-12, 'lHipTransZ': -1.5719654265477768e-10, 'lKneeTransX': 1.0951389687686579e-09, 'lKneeTransY': -1.5697398551593111e-09, 'lKneeTransZ': -0.3682449478582874, 'lAnkleTransX': 7.648554367365156e-06, 'lAnkleTransY': 0.0005271071448347454, 'lAnkleTransZ': -0.4510096621421543, 'lToeTransX': 1.7375551423331664e-10, 'lToeTransY': -0.14747535204639065, 'lToeTransZ': -0.06390597686414445, 'rHipTransX': -0.09831689556149283, 'rHipTransY': -1.9745425829806066e-11, 'rHipTransZ': 1.580670974863694e-10, 'rKneeTransX': -3.1119418414387377e-10, 'rKneeTransY': -1.4823012098561245e-09, 'rKneeTransZ': -0.3682449482594428, 'rAnkleTransX': -0.0004044629470140058, 'rAnkleTransY': 0.0009448278054679095, 'rAnkleTransZ': -0.4497383191636174, 'rToeTransX': -1.3142878526995885e-09, 'rToeTransY': -0.147475346361699, 'rToeTransZ': -0.06390597262765706}\n",
      "(164399, 66)\n",
      "[[-3.91928524e-01  3.37258339e-01  8.74206960e-01]\n",
      " [-1.39286876e-01 -1.00945093e-01 -2.92855060e+00]\n",
      " [-3.53006497e-02  5.32019573e-03  1.35078121e-01]\n",
      " [ 1.05707769e-01 -5.92182009e-02  4.81516510e-02]\n",
      " [ 3.50468563e-01 -1.18246271e-03 -1.24619932e-01]\n",
      " [ 3.76171047e-01 -3.29762720e-02 -1.26710326e-01]\n",
      " [ 7.46855834e-02 -1.18265032e-01  7.94318696e-02]\n",
      " [ 1.14035097e+00  6.88701670e-01 -1.32378511e+00]\n",
      " [-2.60494355e-01  1.28121569e-01 -6.57515265e-01]\n",
      " [-9.83002670e-03 -2.51867367e-01  2.24905002e-01]\n",
      " [ 1.67470257e-01 -5.06570449e-02  2.19130069e-01]\n",
      " [ 7.14533795e-01 -7.68659397e-01  1.52423951e+00]\n",
      " [-9.19399967e-01  1.31008030e-01  1.83107959e-01]\n",
      " [-2.76313929e-01  3.52416165e-01 -1.40832793e-01]\n",
      " [-3.37391806e-01 -9.49250435e-02  5.09271117e-02]\n",
      " [ 3.26189334e-01  1.52098563e-01  9.95321004e-03]\n",
      " [-1.10524820e-01 -1.15389403e-01  1.90082980e-01]\n",
      " [-4.48501738e-02 -1.18593143e-02 -1.88066572e-02]\n",
      " [-1.62625121e-01  2.92339877e-01 -1.51227806e-01]\n",
      " [ 3.28834325e-01 -9.90484908e-02 -2.77811795e-01]\n",
      " [ 2.33913024e-01  7.61932067e-02 -1.93712030e-01]\n",
      " [-7.44455074e-02  7.24456855e-03 -1.66414260e-02]]\n",
      "[-0.39192852  0.33725834  0.87420696] [-0.39192852  0.33725834  0.87420696]\n"
     ]
    }
   ],
   "source": [
    "print(\"The data has dimension timeframe, state_size:\")\n",
    "print(full_traj.data.shape)\n",
    "print(\"\")\n",
    "print(\"This is a list of jointnames (from the urdf) corresponding to the state dimensions:\")\n",
    "print(list(full_traj.description))\n",
    "print(\"\")\n",
    "print(\"Some joints are used for scaling the human and do not change over time\")\n",
    "print(\"They are available in a dictionary:\")\n",
    "print(full_traj.data_fixed)\n",
    "print(full_traj.data.shape)\n",
    "print(full_traj.data[0].reshape((22, 3)))\n",
    "print(full_traj.data[0].reshape((22, 3))[0], full_traj.data.reshape((-1, 22, 3))[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play the trajectory using the pybullet player, we spawn a human and add a trajectory to the human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=3\n",
      "argv[0] = --unused\n",
      "argv[1] = \n",
      "argv[2] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=NVIDIA Corporation\n",
      "GL_RENDERER=NVIDIA GeForce RTX 4080/PCIe/SSE2\n",
      "GL_VERSION=3.3.0 NVIDIA 525.147.05\n",
      "GL_SHADING_LANGUAGE_VERSION=3.30 NVIDIA via Cg compiler\n",
      "pthread_getconcurrency()=0\n",
      "Version = 3.3.0 NVIDIA 525.147.05\n",
      "Vendor = NVIDIA Corporation\n",
      "Renderer = NVIDIA GeForce RTX 4080/PCIe/SSE2\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:48:36\n"
     ]
    }
   ],
   "source": [
    "from humoro.player_pybullet import Player\n",
    "pp = Player()\n",
    "pp.spawnHuman(\"Human1\")\n",
    "pp.addPlaybackTraj(full_traj, \"Human1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A specific frame can be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ven = NVIDIA Corporation\n"
     ]
    }
   ],
   "source": [
    "# pp.showFrame(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or a sequence of frames can be played using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pp.play(duration=360, startframe=3000)\n",
    "# pp.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a possibility to use a Qt5 widget (pp.play_controls()) to allow fast forward and skipping through the file.  It has also some options for segmenting the data. We explain it in the segmentation section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playback multiple humans at same time\n",
    "Often it is useful to display multiple human trajectories at the same time. For example, it can be used to show the output of a prediction and the ground truth at the same time. \n",
    "\n",
    "It can be achieved by spawning a second human and adding a trajectory to it. A trajectory also has an element *startframe*, which tells the player when a trajectory starts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ven = NVIDIA Corporation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 1.36M\n",
      "number of parameters: 1.36M\n",
      "157258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2458/2458 [00:14<00:00, 171.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from model.individual_TF import IndividualTF\n",
    "from model.encoder_decoder_GT import Encoder_Decoder_GPT\n",
    "from model.data_utils import *\n",
    "from model.train_utils import *\n",
    "from model.transformer.batch import subsequent_mask\n",
    "from torch.utils.data import DataLoader\n",
    "from humoro.trajectory import Trajectory\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "joint_dims = 66\n",
    "# joint_dims = 2\n",
    "seq_len = 60\n",
    "target_offset = 60\n",
    "step_size = 60\n",
    "hidden_size = 1024\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "is_cuda = torch.cuda.is_available()\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # TF_model = IndividualTF(enc_inp_size=joint_dims*2, dec_inp_size=(joint_dims*2)+(joint_dims//3), dec_out_size=joint_dims*2, device=device)\n",
    "    # TF_model.load_state_dict(torch.load('model/trained_model_data/TF_1_small_statedict.pt'))\n",
    "    # TF_model.eval()\n",
    "\n",
    "    # obs_dataset = generate_data_from_hdf_file(\"humoro/mogaze/p1_1_human_data.hdf5\", seq_len, target_offset, step_size, use_vel=True)\n",
    "    # train_loader = DataLoader300(obs_dataset, batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "    # model_pred = []\n",
    "    # for x, label in train_loader:\n",
    "    #     x, label = x.to(device).float(), label.to(device).float()\n",
    "\n",
    "    #     target = label[:, :-1, :]\n",
    "    #     # target = x[:, :-1, :]\n",
    "    #     target_c = torch.ones((target.shape[0], target.shape[1], (target.shape[2]//2)//3)).to(device).float()\n",
    "    #     target = torch.cat((target, target_c), -1)\n",
    "    #     start_of_seq = torch.zeros((target.shape[0], 1, target.shape[2])).to(device)\n",
    "    #     start_of_seq[:, :, -1] = 1\n",
    "\n",
    "    #     dec_inp = torch.cat((start_of_seq, target), 1)\n",
    "    #     src_att = torch.ones((x.shape[0], 1, x.shape[1])).to(device).float()\n",
    "    #     trg_att = subsequent_mask(dec_inp.shape[1]).repeat(dec_inp.shape[0],1,1).to(device).float()\n",
    "        \n",
    "    #     out = TF_model(x, dec_inp, src_att, trg_att)\n",
    "    #     model_pred.extend(out[:, -1][:, :66].cpu())\n",
    "    GT_model = Encoder_Decoder_GPT(n_layer=3, n_head=6, n_embd=192, vocab_size=joint_dims, block_size=seq_len, pdrop=0.1, device=device)\n",
    "    GT_model.load_state_dict(torch.load('model/trained_model_data/ED_GT_offset60_direct_statedict.pt'))\n",
    "    GT_model.eval()\n",
    "\n",
    "    obs_dataset = generate_data_from_hdf_file(\"humoro/mogaze/p2_1_human_data.hdf5\", seq_len, target_offset, step_size, use_vel=False)\n",
    "    train_loader = DataLoader(obs_dataset, batch_size=batch_size, num_workers=0, shuffle=False)\n",
    "    print(len(train_loader.dataset))\n",
    "    model_pred_lst = []\n",
    "    for x, label in tqdm(train_loader):\n",
    "        x, label = x.to(device).float(), label.to(device).float()\n",
    "        x_noised = x + torch.normal(mean=0, std=2.5, size=x.shape, device=device)\n",
    "        # out = GT_model.generate(x, 1, do_sample=False)\n",
    "        out, _ = GT_model(x)\n",
    "        # out = out[:, 50:, :]\n",
    "        model_pred_lst.extend(out.cpu())\n",
    "        # print(out.shape, label.shape)\n",
    "        loss = criterion(out, label)\n",
    "        change = criterion(out, x)\n",
    "        # print(loss.cpu(), change.cpu())\n",
    "    # x, label = next(iter(train_loader))\n",
    "    # x, label = x.to(device).float(), label.to(device).float()\n",
    "    # out = GT_model.generate(x, 5000, do_sample=False)\n",
    "    # model_pred.extend(out[:, -1].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157258, 60, 66)\n",
      "(164399, 66)\n"
     ]
    }
   ],
   "source": [
    "# model_pred = np.array(model_pred_lst)[::50, :, 0:66]\n",
    "# model_pred = model_pred.reshape(model_pred.shape[0]*model_pred.shape[1], model_pred.shape[2])\n",
    "print(np.array(model_pred_lst).shape)\n",
    "# print(len(pred_tot_lst[0][0]))\n",
    "# print(np.array(pred_tot_lst).shape)\n",
    "model_pred = np.array(model_pred_lst)[:, -1, 0:66]\n",
    "\n",
    "predicted_traj = Trajectory(model_pred, full_traj.description, full_traj.startframe, full_traj.data_fixed)\n",
    "\n",
    "\n",
    "\n",
    "# pp.spawnHuman(\"TrueFuture\", color=[0., 1., 0., 1.])\n",
    "# # this extracts a subtrajectory from the full trajectory:\n",
    "# sub_traj = full_traj.subTraj(3100, 8100)\n",
    "# sub_traj.startframe = 3000\n",
    "# # we change the startframe of the sub_traj,\n",
    "# # thus the player will play it at a different time:\n",
    "# pp.addPlaybackTraj(sub_traj, \"TrueFuture\")\n",
    "\n",
    "pp.spawnHuman(\"P2_future\", color=[0.5, 0.5, 0., 1.])\n",
    "p2_traj = Trajectory()\n",
    "p2_traj.loadTrajHDF5(\"humoro/mogaze/p2_1_human_data.hdf5\")\n",
    "p2_sub_traj = p2_traj.subTraj(10200, 15200)\n",
    "p2_sub_traj.startframe = 3000\n",
    "pp.addPlaybackTraj(p2_sub_traj, \"P2_future\")\n",
    "\n",
    "print(p2_traj.data.shape)\n",
    "\n",
    "pp.spawnHuman(\"PredFuture\", color=[0., 0., 1., 1.])\n",
    "# this extracts a subtrajectory from the full trajectory:\n",
    "pred_sub_traj = predicted_traj.subTraj(3000, 8000)\n",
    "pred_sub_traj.startframe = 3000\n",
    "# we change the startframe of the sub_traj,\n",
    "# thus the player will play it at a different time:\n",
    "pp.addPlaybackTraj(pred_sub_traj, \"PredFuture\")\n",
    "\n",
    "pp.play(duration=5000, startframe=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Objects\n",
    "There is a helper function to directly spawn the objects and add the playback trajectories to the player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from humoro.load_scenes import autoload_objects\n",
    "obj_trajs, obj_names = autoload_objects(pp, \"humoro/mogaze/p1_1_object_data.hdf5\", \"humoro/mogaze/scene.xml\")\n",
    "pp.play(duration=360, startframe=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access the object trajectories and names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objects:\n",
      "['table', 'cup_red', 'laiva_shelf', 'vesken_shelf', 'plate_blue', 'jug', 'goggles', 'plate_green', 'plate_red', 'cup_green', 'cup_blue', 'red_chair', 'cup_pink', 'plate_pink', 'bowl', 'blue_chair']\n",
      "data shape for first object:\n",
      "(53899, 7)\n"
     ]
    }
   ],
   "source": [
    "print(\"objects:\")\n",
    "print(obj_names)\n",
    "print(\"data shape for first object:\")\n",
    "print(obj_trajs[0].data.shape)  # 7 dimensions: 3 pos + 4 quaternion rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Gaze\n",
    "The gaze can be loaded the following way. Only a trajectory of gaze direction points is loaded, the start point comes from the \"goggles\" object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53900, 3)\n"
     ]
    }
   ],
   "source": [
    "from humoro.gaze import load_gaze\n",
    "gaze_traj = load_gaze(\"humoro/mogaze/p1_1_gaze_data.hdf5\")\n",
    "pp.addPlaybackTrajGaze(gaze_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.play(duration=360, startframe=3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use the raw gaze data, the direction points need to be rotated by the calibration rotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibration rotation quaternion:\n",
      "[-0.31145353  0.37690775 -0.56556629  0.66413253]\n"
     ]
    }
   ],
   "source": [
    "print(\"calibration rotation quaternion:\")\n",
    "print(gaze_traj.data_fixed['calibration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentations\n",
    "The following loads a small Qt5 Application that displays a time axis with the segmentations. The file is segmented into when an object moves.\n",
    "\n",
    "Note that opening the QApplication does not allow to spawn any new objects in pybullet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "setSpacing(self, spacing: int): argument 1 has unexpected type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay_controls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhumoro/mogaze/p1_1_segmentations.hdf5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/humoro-0.1.0-py3.11.egg/humoro/player_pybullet.py:165\u001b[0m, in \u001b[0;36mPlayer.play_controls\u001b[0;34m(self, path_segments)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplay_controls\u001b[39m(\u001b[38;5;28mself\u001b[39m, path_segments\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhumoro\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplay_controls\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     \u001b[43mhumoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplay_controls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartwindow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_segments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_segments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayback_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshowFrame\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_playback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_playback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/humoro-0.1.0-py3.11.egg/humoro/play_controls.py:486\u001b[0m, in \u001b[0;36mstartwindow\u001b[0;34m(path_segments, playback_func, time_start, time_end, fps)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstartwindow\u001b[39m(path_segments\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, playback_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, time_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    485\u001b[0m     app \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQApplication([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlayback Controls\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 486\u001b[0m     window \u001b[38;5;241m=\u001b[39m \u001b[43mWindow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_segments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_segments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayback_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplayback_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m     window\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    488\u001b[0m     app\u001b[38;5;241m.\u001b[39mexec_()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/humoro-0.1.0-py3.11.egg/humoro/play_controls.py:309\u001b[0m, in \u001b[0;36mWindow.__init__\u001b[0;34m(self, path_segments, playback_func, time_start, time_end, fps, parent)\u001b[0m\n\u001b[1;32m    307\u001b[0m widget_vbox \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQWidget()\n\u001b[1;32m    308\u001b[0m vbox \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQVBoxLayout()\n\u001b[0;32m--> 309\u001b[0m \u001b[43mvbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetSpacing\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogicalDpiY\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m96.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m widget_vbox\u001b[38;5;241m.\u001b[39msetLayout(vbox)\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetCentralWidget(widget_vbox)\n",
      "\u001b[0;31mTypeError\u001b[0m: setSpacing(self, spacing: int): argument 1 has unexpected type 'float'"
     ]
    }
   ],
   "source": [
    "pp.play_controls(\"humoro/mogaze/p1_1_segmentations.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label \"null\" means that no object moves at the moment (e.g. when the human moves towards an object to pick it up.\n",
    "\n",
    "It is also possible to directly use the segmentation file, it contains elements of the form (startframe, endframe, label):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2027, b'null')\n",
      "(2027, 2429, b'plate_red')\n",
      "(2430, 2817, b'null')\n",
      "(2818, 3252, b'plate_green')\n",
      "(3253, 3673, b'null')\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(\"humoro/mogaze/p1_1_segmentations.hdf5\", \"r\") as segfile:\n",
    "    # print first 5 segments:\n",
    "    for i in range(5):\n",
    "        print(segfile[\"segments\"][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinematics\n",
    "In order to compute positions from the joint angle trajectory, pybullet can be used. We have a small helper class, which can be used like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=\n",
      "position of right wrist:\n",
      "[0.20642142 0.12073594 0.76067251]\n"
     ]
    }
   ],
   "source": [
    "from humoro.kin_pybullet import HumanKin\n",
    "kinematics = HumanKin()\n",
    "kinematics.set_state(full_traj, 100)  # set state at frame 100\n",
    "print(\"position of right wrist:\")\n",
    "wrist_id = kinematics.inv_index[\"rWristRotZ\"]\n",
    "pos = kinematics.get_position(wrist_id)\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Jacobian can be retreived with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.55111512e-17  7.60672507e-01 -1.20735945e-01  1.00000000e+00\n",
      "  -2.22044605e-16 -1.11022302e-16  1.00000000e+00 -2.22044605e-16\n",
      "  -1.11022302e-16  6.24500451e-17 -2.50631895e-02 -1.08006761e-01\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  1.64496211e-03\n",
      "   1.18043989e-03  1.00134685e-01 -1.07010249e-01 -9.99354955e-01\n",
      "   3.05702598e-02 -1.88449707e-02  1.12179663e-02  3.00429302e-01\n",
      "  -1.08263749e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -9.99223162e-01  3.61791848e-02\n",
      "   1.56249373e-02  1.58090062e-02  4.70170570e-01 -1.53931311e-01\n",
      "  -9.99793879e-01 -9.68145015e-03  1.19375069e-01 -2.45363905e-01\n",
      "  -2.46743136e-01 -9.44927428e-02  1.02494185e-01 -2.43426651e-01\n",
      "  -3.53835300e-02  9.10986680e-01  4.10915167e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-7.60672507e-01 -3.60822483e-16  2.06421420e-01 -2.22044605e-16\n",
      "   1.00000000e+00  5.55111512e-17 -2.22044605e-16  1.00000000e+00\n",
      "   5.55111512e-17  2.57091545e-02 -1.52997581e-03  2.55675343e-01\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  5.98492351e-03\n",
      "  -9.93106893e-02  4.53596860e-04  2.53588915e-01 -3.05033915e-02\n",
      "  -9.99527342e-01 -3.82569412e-03 -3.05283966e-01  9.15638225e-03\n",
      "   2.63956457e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00 -3.61769804e-02 -9.99345309e-01\n",
      "   4.23801433e-04 -4.79434404e-01  3.96621759e-02  2.25083852e-01\n",
      "   1.79179643e-02 -4.81052848e-01  6.08471637e-02  4.29639795e-01\n",
      "  -2.47151767e-02 -5.30562368e-02  2.08569252e-01  1.03973025e-01\n",
      "  -3.84983276e-01 -3.91864602e-01  8.35601586e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [ 1.20735945e-01 -2.06421420e-01  0.00000000e+00 -1.11022302e-16\n",
      "   5.55111512e-17  1.00000000e+00 -1.11022302e-16  5.55111512e-17\n",
      "   1.00000000e+00  1.07854971e-01 -2.55633399e-01 -1.35255640e-03\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  9.99980737e-01\n",
      "  -1.03903052e-01  2.56960600e-01 -1.04664490e-03 -1.89530159e-02\n",
      "  -3.24839085e-03  9.99815098e-01 -1.00170540e-01  2.62470770e-01\n",
      "   1.57994219e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.56300406e-02 -1.41790842e-04\n",
      "   9.99877833e-01 -9.90249376e-02  2.23530666e-01 -2.04252809e-02\n",
      "   9.54702615e-03 -1.11025866e-01  3.07058320e-02  6.33374080e-02\n",
      "   9.68765702e-01 -2.54207285e-02  9.13002229e-02  3.60625146e-02\n",
      "   9.22245023e-01 -1.28628934e-01  3.64580190e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(kinematics.get_jacobian(wrist_id))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
